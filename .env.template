# ===========================================
# DevOps Runbook Assistant - Configuration
# ===========================================
# Skopiuj ten plik jako .env i uzupełnij klucze

# --- LLM Provider (wybierz jeden jako główny) ---
# Opcje: "gemini", "groq", "local"
LLM_PROVIDER=gemini

# --- Google Gemini ---
GOOGLE_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash

# --- Groq (OpenAI-compatible, szybki!) ---
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile

# --- Local Model (wymaga GPU) ---
LOCAL_MODEL_NAME=Qwen/Qwen2.5-1.5B-Instruct
# Dla RTX 4070 można użyć większego modelu:
# LOCAL_MODEL_NAME=Qwen/Qwen2.5-3B-Instruct

# --- Embeddings ---
EMB_MODEL=sentence-transformers/all-MiniLM-L6-v2

# --- Timeouts & Limits ---
TOOL_TIMEOUT_SEC=5.0
MAX_RAG_RESULTS=5
MAX_CONTEXT_CHARS=3000

# --- Security ---
# Dozwolone hosty do pingowania (comma-separated)
ALLOWED_HOSTS=localhost,127.0.0.1,google.com,8.8.8.8
# Dozwolone serwisy
ALLOWED_SERVICES=nginx,postgresql,docker,redis,mysql
